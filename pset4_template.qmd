---
title: "Your Title"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 

## Style Points (10 pts)
## Submission Steps (10 pts)
## Download and explore the Provider of Services (POS) file (10 pts)

1. What are the Variables I pulled? 
```{python}
import pandas as pd 
import altair as alt
import os
import geopandas as gpd
```

```{python}
# Reading dataset
path = "/Users/tsaili-ting/Uchicago/Year2/Y2Fall/Python2/problem-set-4-gena-ting/"

path_2016 = os.path.join(path, "pos2016.csv")
pos2016 = pd.read_csv(path_2016)

#variable pull 

pos2016.columns
```

1. Provider Category
2. Provider Category sub
3. City
4. Hospital Name
5. CMS Number
6. Termination code
7. Termination or Expiration Date
8. ZIP code

2. 
    a. How many hospitals are reported in this data? 
```{python}
pos2016_s = pos2016.loc[(pos2016["PRVDR_CTGRY_CD"]==1)&(pos2016["PRVDR_CTGRY_SBTYP_CD"]==1)]

len(pos2016_s)
```

    The number of short-term hospital in the dataset is 7245.
    
    b.Does this number make sense? Cross-reference with other sources and cite the numberyou compared it to.

     However, according to American Hospital Association(https://www.aha.org/statistics/fast-facts-us-hospitals), there are only 5129 community hospital. Citing that "Excluded are hospitals not accessible by the general public, such as prison hospitals or college infirmaries." in AHA's number. 
    
3. Plot the number of observations in your dataset by year.
```{python}
# Read 2017,18,19 dataset 
path_2017 = os.path.join(path, "pos2017.csv")
path_2018 = os.path.join(path, "pos2018.csv")
path_2019 = os.path.join(path, "pos2019.csv")

pos2017 = pd.read_csv(path_2017)
pos2018 = pd.read_csv(path_2018,encoding="latin1")
pos2019 = pd.read_csv(path_2019,encoding="latin1")

```

```{python}
# filter only short term hospital 
pos2017_s = pos2017.loc[(pos2017["PRVDR_CTGRY_CD"]==1)&(pos2017["PRVDR_CTGRY_SBTYP_CD"]==1)]
pos2018_s = pos2018.loc[(pos2018["PRVDR_CTGRY_CD"]==1)&(pos2018["PRVDR_CTGRY_SBTYP_CD"]==1)]
pos2019_s = pos2019.loc[(pos2019["PRVDR_CTGRY_CD"]==1)&(pos2019["PRVDR_CTGRY_SBTYP_CD"]==1)]

```

```{python}
# Add a column represent the fisical year, and append data

pos2016_s["Year"] = "2016"
pos2017_s["Year"] = "2017"
pos2018_s["Year"] = "2018"
pos2019_s["Year"] = "2019"

# Append the dataset
pos_combine = pd.concat([pos2016_s, pos2017_s, pos2018_s, pos2019_s], ignore_index=True)
```

```{python}
# plot the observations by year
alt.data_transformers.disable_max_rows()
alt.Chart(pos_combine).mark_bar().encode(
    x=alt.X('Year:N',  
            title="Year"),
    y=alt.Y('count()', title="Number of Observation",scale=alt.Scale(domain=[7000, 7500]))
).properties( title='Number of Observations over Year')
```

4. 
    a. Plot the number of unique hospitals in your dataset per year.

```{python}
# aggregate by year and calculate the unique number 
unique_hospital = pos_combine.groupby('Year')['PRVDR_NUM'].nunique().reset_index()
```
```{python}

alt.Chart(unique_hospital).mark_bar().encode(
    x=alt.X('Year:N', title="Year"),
    y=alt.Y('PRVDR_NUM:Q', title="Number of Unique Observations")
    ).properties(
    title='Number of Observations over Year'
)
```

b. Compare this to your plot in the previous step. What does this tell you about the structure of the data?

Look at the two graph they are identical, but we can also check the exact number of each year. 

```{python}
pos_combine.groupby("Year").agg(NumberOfHospital = ("Year","count")).reset_index()
```

```{python}
unique_hospital
```

They are exactly the same number, meaning each row is a unique hospital. 

## Identify hospital closures in POS file (15 pts) (*)

1. 
2. 
3. 
    a.
    b.
    c.

## Download Census zip code shapefile (10 pt) 

1. 
    a.
    - gz_2010_us_860_00_500k.dbf: It's an Attribute Table. This file contains attribute data for each shape (e.g., names, population, or other data related to each spatial feature). It’s essentially a database in a table format and is essential for linking spatial features to their descriptive information.    

    - gz_2010_us_860_00_500k.shp: It's a Shapefile. It contains the geometry data or spatial information. such as the points, lines, or polygons that make up the shape of each feature in the dataset. 

    - gz_2010_us_860_00_500k.xml: It's a Metadata File. This file includes metadata, such as a description of the data, its source, creation date, and other details about the dataset. 

    - gz_2010_us_860_00_500k.prj: It's a Projection File. This file holds information about the coordinate system and projection. It ensures that the shapefile aligns properly on a map with other spatial data.      

    - gz_2010_us_860_00_500k.shx: It's a Shape Index File. This index file is used to facilitate quick access to the geometries in the .shp file. It provides the spatial index of the geometry, helping software read specific features quickly without searching through the entire .shp file.

    b.  
    - gz_2010_us_860_00_500k.dbf: 6.4MB      
    - gz_2010_us_860_00_500k.shp: 837.5MB      
    - gz_2010_us_860_00_500k.xml: 16KM
    - gz_2010_us_860_00_500k.prj: 165bytes      
    - gz_2010_us_860_00_500k.shx: 265KB
2. 

```{python}
# read the shapefile 
filepath = "/Users/tsaili-ting/Uchicago/Year2/Y2Fall/Python2/problem-set-4-gena-ting/gz_2010_us_860_00_500k"
data = gpd.read_file(filepath)
type(data)
```

```{python}
# select Texas zip code, import pandas as pd
data['ZCTA5'] = data['ZCTA5'].astype(int)

# Filter Texas ZIP code range (73301 - 88595)
texas_shp = data[(data['ZCTA5'] >= 73301) & (data['ZCTA5'] <= 88595)]
```

```{python}
# calculate number of zip code under each zip code
pos2016_count = pos2016_s.groupby("ZIP_CD").agg(count = ("FAC_NAME","count")).reset_index()

# filter Texas
pos2016_count_tx = pos2016_count[(pos2016_count['ZIP_CD'] >= 73301) & (pos2016_count['ZIP_CD'] <= 88595)].reset_index()

```

```{python}
# merge shape and hospital by zip code

texas_merged = texas_shp.merge(pos2016_count_tx, left_on='ZCTA5', right_on='ZIP_CD', how='left')

texas_merged['count'] = texas_merged['count'].fillna(0)
texas_merged = texas_merged.drop(columns=['ZIP_CD', 'index'])
```

```{python}
# create choropleth of the number of hospitals by zip code in Texas
texas_merged.plot(column="count", cmap = "Blues",legend=True).set_axis_off()
```

## Calculate zip code’s distance to the nearest hospital (20 pts) (*)

1. 
2. 
3. 
4. 
    a.
    b.
    c.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
2. 
3. 
4. 

## Reflecting on the exercise (10 pts) 
